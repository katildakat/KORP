{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sentences of a corpus/subcorpus available (only) through the Korp interface.\n",
    "\n",
    "Korp is a concordance search tool available for The Swedish Language Bank (https://spraakbanken.gu.se/korp/) and the Language Bank of Finland (https://korp.csc.fi/) collections. It provides its users with an interface to search for keywords in text corpora and to generate concordances for them. There are actually a lot more things you can do with it. You can check them out here: https://www.kielipankki.fi/support/korp/#Search_result_views.\n",
    "\n",
    "However useful Korp is, sometimes you would want to explore a little more than just words and their contexts. For example, you want to trace if the average length of sentences that were written by an author changes through the years. For this, it would be nice to be able to obtain those different kinds of sentences from the corpus. Well, this is how you do it. \n",
    "\n",
    "I would divide the task into three steps:\n",
    "* Download the author subcorpora as multiple CSV files from the Korp interface.\n",
    "* Concatenate the CSV files, get sentences and write them into a .txt file.\n",
    "* Check that you've got everything right (or rightish). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the subcorpora as multiple CSV files from the Korp interface.\n",
    "* 1. Go to Korp and select the corpus you need. For example, New year's speeches given by the presidents of Finland (https://metashare.csc.fi/repository/browse/new-years-speeches-of-the-presidents-of-the-republic-of-finland/6d69dc8e089a11e28bed005056be118e41f01f1cea2f47c3b6bd34181fb18aa7/). Let's select only Tarja Halonen's speeches.\n",
    "<img src= \"screens/screen1.png\">\n",
    "* 2. Press on **Extended** search, select KWIC hits per page, and the statistics you want to base the corpora division on. For example, **1000** KWIC hits per page (this would result in the smallest number of CSV parts), and **date**. Hit **Search**.\n",
    "<img src= \"screens/screen2.png\">\n",
    "* 3. Go to **Statistics** tab and press on the year you are interested in (2001, for example). The interface will open an additional KWIC tab.\n",
    "<img src= \"screens/screen3.png\">\n",
    "<img src= \"screens/screen4.png\">\n",
    "* 4. Scroll till the bottom of the new KWIC tab. You'll see a **Download KWIC** button. Select **Sentence per row, match and contexts separated** and **CSV** as your data and file formats next to the button. Press the **Download KWIC** button to start the download.\n",
    "<img src= \"screens/screen5.png\">\n",
    "* 5. Go page by page and download the rest of the files.\n",
    "<img src= \"screens/screen6.png\">\n",
    "\n",
    "NOTE1: These steps can be automated with Selenium web driver, for example.\n",
    "NOTE2: Sometimes in Korp you can get as much as paragraphs of text. For this, after step 3 press **Show context** next to the pagination bar in the new KWIC tab.\n",
    "<img src= \"screens/screen7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concatenate the files, get sentences and write them into a .txt file.\n",
    "* 1 Concatenate CSV files into one dataframe.\n",
    "* 2 Select only rows with empty left context (start of the sentence). \n",
    "* 3 Create a column that contains full sentences.\n",
    "* 4 Convert this column into a list of strings.\n",
    "* 5 Write this list into a .txt file.\n",
    "\n",
    "NOTE: in the case of presidential speeches, you have a \"sentence_id\" feature that you can use to extract sentences. Not all corpora in Korp have this, so I am describing a more general case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit number</th>\n",
       "      <th>corpus</th>\n",
       "      <th>left context</th>\n",
       "      <th>match</th>\n",
       "      <th>right context</th>\n",
       "      <th>left context lemmas</th>\n",
       "      <th>match lemmas</th>\n",
       "      <th>right context lemmas</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_distributor</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_span</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_url</th>\n",
       "      <th>URN</th>\n",
       "      <th>metadata link</th>\n",
       "      <th>licence</th>\n",
       "      <th>date</th>\n",
       "      <th>total hits</th>\n",
       "      <th>Korp URL</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KOTUS_NS_PRESIDENTTI_HALONEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vuosituhannen</td>\n",
       "      <td>vaihtuminen lisäsi keskustelua elämämme arvois...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vuosituhat</td>\n",
       "      <td>vaihtuminen lisätä keskustelu elämä arvo .</td>\n",
       "      <td>Tasavallan presidentin uudenvuodenpuhe 1.1.2001</td>\n",
       "      <td>Kotimaisten kielten tutkimuskeskus / Research ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MENNYT</td>\n",
       "      <td>s0</td>\n",
       "      <td>http://kaino.kotus.fi/korpus/teko/teksti/presi...</td>\n",
       "      <td>urn:nbn:fi:lb-20151001</td>\n",
       "      <td>http://urn.fi/urn:nbn:fi:lb-20140730150</td>\n",
       "      <td>EUPL v1.1 (CLARIN PUB)</td>\n",
       "      <td>2020-09-18 17:21:59</td>\n",
       "      <td>1243</td>\n",
       "      <td>https://korp.csc.fi/#?stats_reduce=text_date&amp;c...</td>\n",
       "      <td>corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KOTUS_NS_PRESIDENTTI_HALONEN</td>\n",
       "      <td>Vuosituhannen</td>\n",
       "      <td>vaihtuminen</td>\n",
       "      <td>lisäsi keskustelua elämämme arvoista .</td>\n",
       "      <td>vuosituhat</td>\n",
       "      <td>vaihtuminen</td>\n",
       "      <td>lisätä keskustelu elämä arvo .</td>\n",
       "      <td>Tasavallan presidentin uudenvuodenpuhe 1.1.2001</td>\n",
       "      <td>Kotimaisten kielten tutkimuskeskus / Research ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MENNYT</td>\n",
       "      <td>s0</td>\n",
       "      <td>http://kaino.kotus.fi/korpus/teko/teksti/presi...</td>\n",
       "      <td>urn:nbn:fi:lb-20151001</td>\n",
       "      <td>http://urn.fi/urn:nbn:fi:lb-20140730150</td>\n",
       "      <td>EUPL v1.1 (CLARIN PUB)</td>\n",
       "      <td>2020-09-18 17:21:59</td>\n",
       "      <td>1243</td>\n",
       "      <td>https://korp.csc.fi/#?stats_reduce=text_date&amp;c...</td>\n",
       "      <td>corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KOTUS_NS_PRESIDENTTI_HALONEN</td>\n",
       "      <td>Vuosituhannen vaihtuminen</td>\n",
       "      <td>lisäsi</td>\n",
       "      <td>keskustelua elämämme arvoista .</td>\n",
       "      <td>vuosituhat vaihtuminen</td>\n",
       "      <td>lisätä</td>\n",
       "      <td>keskustelu elämä arvo .</td>\n",
       "      <td>Tasavallan presidentin uudenvuodenpuhe 1.1.2001</td>\n",
       "      <td>Kotimaisten kielten tutkimuskeskus / Research ...</td>\n",
       "      <td>...</td>\n",
       "      <td>MENNYT</td>\n",
       "      <td>s0</td>\n",
       "      <td>http://kaino.kotus.fi/korpus/teko/teksti/presi...</td>\n",
       "      <td>urn:nbn:fi:lb-20151001</td>\n",
       "      <td>http://urn.fi/urn:nbn:fi:lb-20140730150</td>\n",
       "      <td>EUPL v1.1 (CLARIN PUB)</td>\n",
       "      <td>2020-09-18 17:21:59</td>\n",
       "      <td>1243</td>\n",
       "      <td>https://korp.csc.fi/#?stats_reduce=text_date&amp;c...</td>\n",
       "      <td>corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit number                        corpus               left context  \\\n",
       "0           0  KOTUS_NS_PRESIDENTTI_HALONEN                        NaN   \n",
       "1           1  KOTUS_NS_PRESIDENTTI_HALONEN              Vuosituhannen   \n",
       "2           2  KOTUS_NS_PRESIDENTTI_HALONEN  Vuosituhannen vaihtuminen   \n",
       "\n",
       "           match                                      right context  \\\n",
       "0  Vuosituhannen  vaihtuminen lisäsi keskustelua elämämme arvois...   \n",
       "1    vaihtuminen             lisäsi keskustelua elämämme arvoista .   \n",
       "2         lisäsi                    keskustelua elämämme arvoista .   \n",
       "\n",
       "      left context lemmas match lemmas  \\\n",
       "0                     NaN   vuosituhat   \n",
       "1              vuosituhat  vaihtuminen   \n",
       "2  vuosituhat vaihtuminen       lisätä   \n",
       "\n",
       "                         right context lemmas  \\\n",
       "0  vaihtuminen lisätä keskustelu elämä arvo .   \n",
       "1              lisätä keskustelu elämä arvo .   \n",
       "2                     keskustelu elämä arvo .   \n",
       "\n",
       "                                        text_title  \\\n",
       "0  Tasavallan presidentin uudenvuodenpuhe 1.1.2001   \n",
       "1  Tasavallan presidentin uudenvuodenpuhe 1.1.2001   \n",
       "2  Tasavallan presidentin uudenvuodenpuhe 1.1.2001   \n",
       "\n",
       "                                    text_distributor  ... paragraph_span  \\\n",
       "0  Kotimaisten kielten tutkimuskeskus / Research ...  ...         MENNYT   \n",
       "1  Kotimaisten kielten tutkimuskeskus / Research ...  ...         MENNYT   \n",
       "2  Kotimaisten kielten tutkimuskeskus / Research ...  ...         MENNYT   \n",
       "\n",
       "   sentence_id                                       sentence_url  \\\n",
       "0           s0  http://kaino.kotus.fi/korpus/teko/teksti/presi...   \n",
       "1           s0  http://kaino.kotus.fi/korpus/teko/teksti/presi...   \n",
       "2           s0  http://kaino.kotus.fi/korpus/teko/teksti/presi...   \n",
       "\n",
       "                      URN                            metadata link  \\\n",
       "0  urn:nbn:fi:lb-20151001  http://urn.fi/urn:nbn:fi:lb-20140730150   \n",
       "1  urn:nbn:fi:lb-20151001  http://urn.fi/urn:nbn:fi:lb-20140730150   \n",
       "2  urn:nbn:fi:lb-20151001  http://urn.fi/urn:nbn:fi:lb-20140730150   \n",
       "\n",
       "                  licence                 date total hits  \\\n",
       "0  EUPL v1.1 (CLARIN PUB)  2020-09-18 17:21:59       1243   \n",
       "1  EUPL v1.1 (CLARIN PUB)  2020-09-18 17:21:59       1243   \n",
       "2  EUPL v1.1 (CLARIN PUB)  2020-09-18 17:21:59       1243   \n",
       "\n",
       "                                            Korp URL  \\\n",
       "0  https://korp.csc.fi/#?stats_reduce=text_date&c...   \n",
       "1  https://korp.csc.fi/#?stats_reduce=text_date&c...   \n",
       "2  https://korp.csc.fi/#?stats_reduce=text_date&c...   \n",
       "\n",
       "                                              params  \n",
       "0  corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...  \n",
       "1  corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...  \n",
       "2  corpus=KOTUS_NS_PRESIDENTTI_HALONEN; cqp=[]; d...  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the parts of the corpus\n",
    "paths = sorted(glob.glob('2001/*')) # i've collected the parts of 2001 speech into a folder '2001'\n",
    "# reading every csv file into a dataframe\n",
    "dfs = [pd.read_csv(paths[i]) for  i in range(len(paths))]\n",
    "# concatenating dataframes\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# quick look at the dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only text columns\n",
    "sentences = df[['left context','match','right context']]\n",
    "# selecting only the rows where 'match' starts the sentence (no left context)\n",
    "sentences = sentences[sentences['left context'].isnull()]\n",
    "# ignoring empty matches (if there are, korp has such mistakes in some corpora)\n",
    "sentences = sentences[sentences['match'].notnull()]\n",
    "# converting remaining empty cells into empty strings \n",
    "# (for empty right contexts, if a sentence is one word)\n",
    "sentences = sentences.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column with full sentences \n",
    "# by concatenating matches and their right contexts\n",
    "sentences['full sentence'] = sentences['match'] + ' ' +  sentences['right context'] + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tehkäämme vuodesta 2001 aidosti yhteisen vastuun vuosi .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting the column with sentences into a list\n",
    "corpus = sentences['full sentence'].tolist()\n",
    "\n",
    "# quick look at the last sentence\n",
    "print(corpus[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.open('2001.txt', 'w', encoding='UTF-8')\n",
    "f.writelines(corpus)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Check that you've got everything right.\n",
    "This step helps to make sure there were no really dumb mistakes. We'll compare the number of tokens in sentences to the number of 'match' tokens in the CSV files.\n",
    "\n",
    "* 1 Split the sentences from step 2 by whitespaces and count the tokens.\n",
    "* 2 Compare this count to the number of match tokens in the concatenated dataframe.\n",
    "    * Get tokens from 'match' column.\n",
    "    * Count the number of whitespaces these tokens contain. (One match token can contain whitespaces, so we can't just compare the number of rows in the dataframe to the number of tokens from a previous step (3.1))\n",
    "    * Subtract the whitespace count from the token count in the sentences. Compare this number to the number of match tokens.\n",
    "* 3 Manually check the number of tokens to the number given in Korp to be completely sure that you've got everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243\n"
     ]
    }
   ],
   "source": [
    "# count whitespace separated tokens\n",
    "n = 0\n",
    "for sent in corpus:\n",
    "    n += len(sent.split())\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1243\n"
     ]
    }
   ],
   "source": [
    "# get match tokens and count how many whitespaces they contain    \n",
    "match_tokens = df['match'].tolist()\n",
    "k = 0\n",
    "for word in match_tokens:\n",
    "    if len(word.split()) > 1:\n",
    "        k+= len(word.split()) - 1\n",
    "        \n",
    "# compare token counts\n",
    "print(n-k == len(match_tokens))\n",
    "print(len(match_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "1243 is exactly the same as the number of tokens in Korp:\n",
    "<img src= \"screens/screen8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL NOTES\n",
    "\n",
    "Now you can do the same thing with speeches from other years. Not all corpora in Korp are as nice as this one, so you'll probably need to make some modifications to the code.\n",
    "\n",
    "You can find the functions based on steps taken in this notebook in write_korp_corpus.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
